## 入门命令的探索

### 基本命令尝试


```
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
```

 这是一个创建topic的命令，目前broker的数量是1，我尝试了下replication-factor >1 的情况，发现不能创建成功，即副本的单位是每个broker。另外尝试了partitions>1的情况，发现可以创建成功。    
 结论： 1个broken上只能创建一份副本，可以创建多个分区    
 

```
Topic:test  PartitionCount:1    ReplicationFactor:1 Configs:
    Topic: test Partition: 0    Leader: 0   Replicas: 0 Isr: 0
    
Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: my-replicated-topic  Partition: 0    Leader: 1   Replicas: 1,2,0 Isr: 1,2,0
```
这是两个describe命令的结果，可以看到其一test, ReplicationFactor为1，所以只有一个副本，即故Leader，Replicas，Isr都为id为0的broker。其二my-replicated-topic ，其ReplicationFactor为3，故在id为0，1，2的broker上都有副本。

+ “leader”是负责给定分区的所有读取和写入的节点。每个节点将成为随机选择的分区部分的引导者。
+ “replicas”是复制此分区的日志的节点列表，无论它们是领先者还是目前都是活着的。
+ “isr”是一组“同步”副本。这是replicas的子集，该列表表示目前是活跃的有效的，并且被追加到领导者。


```
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 2 --topic twomultwotest

Topic:twomultwotest	PartitionCount:2	ReplicationFactor:2	Configs:
	Topic: twomultwotest	Partition: 0	Leader: 0	Replicas: 0,1	Isr: 0,1
	Topic: twomultwotest	Partition: 1	Leader: 1	Replicas: 1,2	Isr: 1,2
```

上述实验是，当前broker为3，新建的topic副本为2，分区为2，可以看到describe的结果，topic的分区有0和1，分区为0的，在broker0，1上，分区为1的，在broker1，2上。刚开始有点疑惑，因为副本设置为2，但很明显涉及到了3个broker,那不是有3个副本，仔细想想其实不然，broker上存放的是partition的数据，topic有两个分区，每个分区在两个broker上有副本，所以最后加起来topic只有2个副本，只是以partition为单位分散到了不同的broker上。

对my-replicated-topic的实验表明，在多个broker之间，某个broker挂掉了，会选取另外的broker作为新的Leader, 并不影响继续工作。


```
./bin/kafka-topics.sh  --zookeeper  localhost:2181 --delete --topic tt
Topic tt is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
```
目前删除操作在默认情况下只是打上一个删除的标记，在重新启动kafka 后才删除。如果需要立即删除，则需要在server.properties中配置delete.topic.enable=true

### 主要参数解释

#### partitions分区数

+ partitions ：分区数，控制topic将分片成多少个log。可以显示指定，如果不指定则会使用broker(server.properties)中的num.partitions配置的数量 
+ 虽然增加分区数可以提供kafka集群的吞吐量、但是过多的分区数或者或是单台服务器上的分区数过多，会增加不可用及延迟的风险。因为多的分区数，意味着需要打开更多的文件句柄、增加点到点的延时、增加客户端的内存消耗。
+ 分区数也限制了consumer的并行度，即限制了并行consumer消息的线程数不能大于分区数 
+ 分区数也限制了producer发送消息是指定的分区。如创建topic时分区设置为1，producer发送消息时通过自定义的分区方法指定分区为2或以上的数都会出错的；这种情况可以通过alter –partitions 来增加分区数。

#### replication-factor副本

+ replication factor 控制消息保存在几个broker(服务器)上，一般情况下等于broker的个数。 
+ 如果没有在创建时显示指定或通过API向一个不存在的topic生产消息时会使用broker(server.properties)中的default.replication.factor配置的数量 


--

### KafKa项目结构

+ core

	core下面的应该是kafka的源码。使用scala写的，经编译后生成jar包，在kafka安装包下bin/*.sh的脚本，如kafka-topics.sh，作用便是执行jar程序。
	
+ connect

	>The Connect API allows implementing connectors that continually pull from some source system or application into Kafka or push from Kafka into some sink system or application.
	
	一种可扩展的和可靠的连接Kafka框架与外部系统（如数据库，键值存储，搜索索引和文件系统）的框架。除了Kafka以外， Confluent Platform 包括更多的工具和服务，使构建和管理数据流平台更加容易。

	
+ clients

	Java 库，写消息到kafka 或者从kafka 读消息
	
+ streams

	> allows transforming streams of data from input topics to output topics.
	
	Kafka Streams是一个库使kafka转换成功能齐全的流处理系统。
	

### confluent 

+ Confluent Kafka Connectors

	连接SQL数据库/Hadoop/Hive
	
+ Confluent Kafka Clients

	对于其他编程语言，包括C/C++,Python
	
+ Confluent Kafka REST Proxy

	允许一些系统通过HTTP和kafka之间发送和接收消息。
	
+ Confluent Schema Registry

	帮助确定每一个应用使用正确的schema当写数据或者读数据到kafka中。