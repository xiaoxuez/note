以下参考源自http://www.cnblogs.com/skyme/archive/2011/10/28/2226850.html

##框架

Hadoop使用主/从（Master/Slave）架构，主要角色有NameNode，DataNode，secondary NameNode，JobTracker，TaskTracker组成。
其中NameNode，secondary NameNode，JobTracker运行在Master节点上，DataNode和TaskTracker运行在Slave节点上。  

1. NameNode。NameNode是HDFS的守护程序，负责记录文件是如何分割成数据块的，以及这些数据块被存储到哪些数据节点上。它的功能是对内存及I/O进行集中管理。
2. DataNode。集群中每个从服务器都运行一个DataNode后台程序，后台程序负责把HDFS数据块读写到本地文件系统。需要读写数据时，由NameNode告诉客户端去哪个DataNode进行具体的读写操作。
3. Secondary NameNode。Secondary NameNode是一个用来监控HDFS状态的辅助后台程序，提供周期检查点和清理任务。如果NameNode发生问题，可以使用Secondary NameNode作为备用的NameNode。
4. JobTracker。JobTracker后台程序用来连接应用程序与Hadoop，用户应用提交到集群后，由JobTracker决定哪个文件处理哪个task执行，一旦某个task失败，JobTracker会自动开启这个task。负责调度datanode上的工作。每个 datanode 有一个 tasktracker，它们执行实际工作。jobtracker 和 tasktracker 采用主-从形式，jobtracker 跨 datanode 分发工作，而 tasktracker 执行任务。jobtracker 还检查请求的工作，如果一个 datanode 由于某种原因失败，jobtracker 会重新调度以前的任务


##HDFS

  hadoop distributed file system   分布式文件系统
  

## 常用命令

hadoop dfs -ls 列出HDFS下的文件
hadoop dfs -ls in 列出HDFS下某个文档中的文件
hadoop dfs -put test1.txt test 上传文件到指定目录并且重新命名，只有所有的DataNode都接收完数据才算成功
hadoop dfs -get in getin 从HDFS获取文件并且重新命名为getin，同put一样可操作文件也可操作目录
hadoop dfs -rmr out 删除指定文件从HDFS上
hadoop dfs -cat in/* 查看HDFS上in目录的内容
hadoop dfsadmin -report 查看HDFS的基本统计信息，结果如下
hadoop dfsadmin -safemode leave 退出安全模式
hadoop dfsadmin -safemode enter 进入安全模式


## 添加节点

  首先在新加的节点上安装hadoop，然后修改$HADOOP_HOME/conf/master文件，加入NameNode主机名，然后在NameNode节点上修改$HADOOP_HOME/conf/slaves文件，加入新加节点主机名，再建立到新加节点无密码的SSH连接。

## 运行启动命令：

start-all.sh

然后可以通过http://(Master node的主机名):50070查看新添加的DataNode


##负载均衡

start-balancer.sh，可以使DataNode节点上选择策略重新平衡DataNode上的数据块的分布


## 工作流程

　NameNode节点作为Master服务器，有三部分功能。第一：处理来自客户端的文件访问。第二：管理文件系统的命名空间操作，如'打开'、'关闭'、'重命名'等。第三：负责数据块到数据节点之间的映射。从这个意义上说，它扮演中心服务器的角色。   
　     
　 DataNode节点作为Slave服务器，同样有三部分功能。第一：管理挂载在节点上的存储设备。第二：响应客户端的读写请求。第三：从内部 看，每个文件被分成一个或多个数据块，被存放到一组DataNode，在Namenode的统一调度下进行数据块的创建、删除和复制。     
　     
　 一个典型的部署场景是，一台GNU/Linux操作系统上运行一个Namenode实例，作为Master中 心服务器。而集群中的其它GNU/Linux操作系统分别运行一个Datanode实例，作为Slave服务器集群。
　 
## MapReduce编程模型

从概念上来讲，MapReduce将输入元素列表(Input List)转换成输出元素列表(Output List)，按照Map与Reduce规则各一次